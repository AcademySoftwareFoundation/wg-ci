---
title: 2022-09-14
parent: Meetings
---
# ASWF CI Working Group

Meeting:   14 September 2022 \

[https://zoom-lfx.platform.linuxfoundation.org/meeting/97730566101](https://zoom-lfx.platform.linuxfoundation.org/meeting/97730566101)

## Attendees

* Jean-Francois Panisset (VES Technology Committee)
* Jean-Christophe Morin
* Larry Gritz (Sony Imageworks)
* Aloys Baillet (NVIDIA)
* John Mertic, Linux Foundation
* Andrew Grimberg, LF Release Engineering
* Ryan Botriell, ILM
* Dan Bailey, OpenVDB

## Apologies

*

## New items

* GitHub Actions enhanced builders (Andrew, Aloys)
    * [GitHub Actions Larger runners - Are now in public beta | GitHub Changelog](https://github.blog/changelog/2022-09-01-github-actions-larger-runners-are-now-in-public-beta/)
    * Free access until end of September, we start paying on October 1st.
    * Successful Qt build
        * It works, one question is that I had to switch the GitHub to use that runner, but every release build will go through that. Some packages that don't need it and can run on free runners, how can I tag specific jobs to go on for pay runner. Andrew: will need to rewrite / split the jobs so only the jobs that need it require the runs-on to the for-pay runners.
        * Aloys: not sure how to select the runs-on for the release builds. Maybe multiple release jobs.
        * Not clear how to set up GHA matrix to support unavailable runners when building outside of ASWF org. [Reusable Workflows](https://docs.github.com/en/actions/using-workflows/reusing-workflows) currently don't support templating "runs-on". Andrew: brought this up with GitHub, need to be able to template the "runs-on" for workflows, job can run on free runners, but runs more efficiently on the paid ones. Don't have an answer for that. Would be running into same issue with self-hosted runners, this looks like a self hosted runner, but it's being managed by GitHub instead of by us. With self hosted, need to pay for full time resource use, as well as management cost.
        * Dan: in some workflows, we have to approve people running CI jobs, someone who hasn't committed to the repo before. Andrew: yes, that's a default thing for GitHub, users need to have met some criteria. OCIO CodeBuild builds are triggered build, have to be triggered by someone when they do a release, only some people have those rights. One way of limiting when we utilize those resources.
        * Ryan: there are bots that can do that for you if a maintainer puts the right comment on a PR.
        * Dan: we only one of each for Windows and Linux runners? Andrew: set the usability to "2", we do not pay for anything we aren't utilizing, one is always running, but can have a second instance get spun up. Could set it to 1, which would limit to serial builds. Dan: free GHA limits to 10 concurrent runners? Andrew: can increase the number, but there may be cost implications. Having the limit low is mostly for testing. Dan: where and how should we be using this, it's useful for all our builds. Andrew: Aloys wasn't able to get a build done within free limits, and GPU will only be accessible via premium runners. Big question is: is there a major benefit to your project to running on a larger instance, have enough changes coming in that you are constantly waiting in queue since we are consuming all our free time, adding premium runners would make sense. Dan: sometimes build take a very long time, have to constrain to a single core for memory limitations. Andrew: yes, that would make premium runners a good use if you are running into major constraints. We just have to take into consideration the budget. We don't want to spend money where we don't have to. John: we would need some predictability so we understand the costs involved. Dan: for OpenVDB, it's very valuable, had to slim down the build matrix, all our builds would benefit for more cores. Is there a benefit to running on 4 vs 16, don't get a 16x build improvement on a 16 core machine. So could limit to smaller configs. Andrew: also have access to 4, 8 and 64 core systems, have options on sizing. Initial attempt was how this would help. Also basing on what we have configured for CodeBuild.
        * JF: what about performance regression testing? Dan: some of the more expensive performance tests have to be opted in, and typically don't run it on build farm. Even if unit tests are using multi-threaded algorithms, won't catch race conditions on a single thread, so definitely having more than one would be good, but may not be a significant improvement to run on 16 cores rather than 4. Andrew: but there is a time/cost tradeoff, sometimes it's cheaper to run on the bigger system. We do this analysis for some of our other projects that are fully managed. We can do that here as well. I can build a couple of the smaller instances and try those, so we can see if there's benefit from the larger systems, and what's the sweet spot. If you are using premium runners for validation of PRs, want to have the smallest matrix that will hit the most test cases. As PRs get merged in, can use larger runner to run more extensive tests. Dan: regular CI is much more constrained than weekly one, but sometimes we catch new issues only after that weekly run. For OpenVDB, would be useful to have more relatively smaller machines rather than one much larger one. Andrew: will build a few more to test. Dan: also a CUDA related issue that needs to be fixed, assess how much its costing. Build time is variable due to ccache, if you modify top level header, could take 60m-90m for a build, but at the leaf level, could be only a few minutes. Don't want the user to have to pick the type of runner. Ryan: in your GitHub CI files, you can specify which workflow to run based on which file is changed, so could pick larger vs smaller runner. Dan: sounds like it could be complicated to setup. Have some whitespace checks that can run on smaller instances, but not as granular as per file.
        * Andrew: building these 4C/8C runners for Ubuntu and Windows:
            * ubuntu-20.04-4c-16g-150h (max 50)
            * ubuntu-20.04-8c-32g-300h (max 25)
            * windows-2022-8c-32g-300h (max 25) (no 4C option for Windows)
    * How do we get other projects to try them out? Only aswf-docker and openvdb for now have access.
        * ubuntu-20.04-16c-64g-600h (available to both repos) and windows-2022-16c-64g-600h (available to just openvdb currently)
        * 16 CPU, 64G RAM, and 600G disk space
        * Dan: Everything feels much faster and Iâ€™ve been able to successfully remove the thread cap we had to apply for certain builds due to the higher memory available on these runners. The Windows builds do not use ccache currently and went from 1h10m to build down to just 10m (going from 2 threads to 16 threads). They are a bit slower to startup and I definitely notice only having one runner available for linux and windows respectively.
        * JC: Following the GitHub Actions security model, only builds in the context of the ASWF will be able to use the runners. We certainly don't want anyone to push stuff in their forks that would lead to utilize all the ASWF resources. In this case, PR builds would have access to the runner but not push builds in forks.

    * Andrew: cost estimate is 50% less than CodeBuild. Currently averaging $220/month for OCIO GPU runs on Codebuild (no GPU runner available yet)
    * Andrew: most of our time is spent waiting for a GPU instance to become available (GPU instance availability different per region). For OCIO, 55m total run time vs 3m actual build time on CodeBuild. Sean Looper / Sean Wallitsch / Esteban Papp may be able to help interface with CodeBuild team to make setup less complicated.
    * OCIO no longer running GPU tests on CodeBuild?
        * Last main branch PR merged 2 months ago, which would have triggered the GPU test
    * How best to target potential AWS credits? (DPEL vs CodeBuild). Approach Microsoft for GH Builder credits?
        * Andrew: on an annual basis, a project can petition AWS for credits. Process can be a bit opaque, sometimes get a lump sump of credits that can be applied to a project. All projects are structurally connected to LF at a billing level, but can apply credits at the ASWF level. But currently no ASWF credits. Typically application is around March.
        * Using GitHub Premium Runners is significantly less overhead. Microsoft / GitHub currently doesn't have a credits program we could apply into, the GitHub ASWF org was enabled as an Enterprise level org at no charge, so we have access to a larger number of runners and free minutes, and larger storage allocation, so already getting that. JC: before the change, jobs were always being queued, after the change to Enterprise, we've seen much faster turnaround, a lot fewer queuing issues. Maybe worth mentioning to the TAC. But not a general program, not a formal process like AWS credits process.
        * Dan: access to Mac runners? Andrew: GitHub Actions team doesn't have access to mac runners yet due to availability in Azure. Andrew: we need M1/M2 runners, and we need GPUs, remind them every month. GPU should be coming out in next quarter and we should be in early Alpha. Also when Mac runners become available, they should be made available in the Alpha. They are aware that ASWF has a need for all these platforms since all our downstream consumers use all these platforms.
        * Andrew: have meeting with GitHub team once a month, LF RelEng team in regular communications. 2 months ago had the head of GitHub Actions come talk to us.
* ASWF Docker updates (Aloys)
* Review of CII badge requirements - cont (John Mertic)
    * Review and annotate background document: [https://docs.google.com/document/d/1oncI0hbkreAefeidUmbwB_Tl36UNFzI88SbVDe1oKOg/edit#heading=h.agfhwzg33dmj](https://docs.google.com/document/d/1oncI0hbkreAefeidUmbwB_Tl36UNFzI88SbVDe1oKOg/edit#heading=h.agfhwzg33dmj)
    * What can wg-ci do to help projects meet requirements
    * Identify specific examples in current projects that new projects can use
    * Perhaps create a spreadsheet pointing to specific examples
    * Present back to TAC on feasibility of increased requirements for new projects
    * Restructure as a spreadsheet for the project leaders
    * Start with looking at Gold
        * John: clarifications from CII requirement authors?
        * Got to "Test Suite" at last meeting, pick up at Security
        * Larry: under change control, is 2FA taken care of by GitHub? Andrew: we enforce it for ASWF Organization members, so if the project isn't under ASWF org in GitHub, that could be an issue, but easy to fix. But will boot everyone out of the organization. But relatively easy to add them back in.
        * John: most project communities gravitate towards using personal identities. For LF ID Profiles, tend to see more people use their personal, since their contribution to open source goes across employments. But sometimes need to separate contributions. Everyone has to figure out what's best. But 2FA is handled.
        * John: Had time with David Wheeler. For reproducible builds, couple of ways to solve this. Within project jurisdictions themselves, are the projects distributing binaries? Larry: most are not, some are. John: one of the ways to resolve this is that if you don't distribute binaries, this doesn't apply to you. Larry: Kind of a halfway fix, for OSL, we don't distribute binaries, but so many people have trouble building on Windows, that as an aspirational goal, we are aiming for a "one step install". Nowhere close to that, but will bubble up. John: which is fair, if you get to this point, there are other considerations around distribution binaries, there's the dependency aspect since you are distributing third party open source code, and depending on the license, there are some concepts for various licenses that are intended for source code but don't translate well to binaries. Also in some communities, when you give a binary, it implies you support that binary, or sometimes get downstream vendors that will bundle that binary. There are projects which went down that path, there are things we can setup to mitigate / encapsulate some of the potential risk. Something we want to think about.
        * John: also can provide instructions of how one can get a reproducible build, document the sources of variance, or just provide a script like a Linux package manager does.
        * John: not a perfect answer, but when a project gets into the area of binaries, opening up a can of worms.
        * Larry: OCIO, OTIO have produced Python wheels, not sure if that falls under that category. Andrew: if they are distributing via PyPI, we would want to check into this.
        * John: there should be a path that two people can do builds independently and end up in the same place. The rationale is that if you go down the same path, there are no changes of security attacks, gives you a degree of confidence that you could reproduce the same as what the maintainers produce.
        * Test coverage: will be useful for projects to do a self assessment, where they are at, and how much more coverage they can get. Larry: got the SonarCloud set up for OSL, get about 75% measured in lines, not sure about branches, close enough to 80% mark that disabling a couple of things that can't be tested and adding a couple more test, could get to 80% in a reasonably straightforward way.  John: branch coverage is harder. Larry: got better result than expected with instruction coverage. John: if you are getting into lots of area with code that's hard to reach, or architecture based, could potentially be setting yourself up with having trouble maintaining that code, there may be areas where re-architecting those areas may make it more possible to support (understanding that this is easier said than done). But it may make it easier to support your code.
        * Larry: our CI test will test a bunch of different configurations, stuff that's enabled / disabled, across entire CI test suite get higher coverage than across a single suite that goes into Coverage Analysis, don't necessarily a case of code that's never touched, it's just hard to make one compile touch all that code. John: can use the "law of averages" to get you there. JC: codecov can merge results from different runs, SonarCloud may do as well but not as straightforward.
        * Use basic good cryptographic practices
            * Secure network protocols. Larry: most of our projects don't have network communications, except for OpenCue.
            * Limit to TLS 1.2
        * Secured delivery
            * If you are hosting on GitHub, you should be fine
        * Other security issues
            * There are resources for security audits, ASWF can and should fun, and there may be OpenSSF funding available. They have project Alpha Omega which helps do assessments of projects that need a lot of help, funding and resources.
            * Hardening mechanisms: what does that mean? What does "hardening" specifically mean? May include compiler flags, maybe some CI runs build with it, or does it mean default compiler flags? Can look at some sample projects like curl. Can also make improvements to the code base. Curl run tests against it continuously to catch issues that would invalidate it.  Ryan: feels like you need to be aware of potential attack vectors and have tried to address those. Larry: not sure many of our projects are aware of potential attack vectors. John: may also tie in to requirement for security expertise. Larry: we may lack the imagination. Someone who knows more about vulnerabilities and what bad actors may try, there may be avenues of attack that haven't occurred to us. John: a lot of it is thinking along those lines, recognizing that over time, new avenues of attack will pop up. Some projects do it as part of code review, some do it as part of testing.
        * Dynamic Code Analysis
            * SonarCloud is static analysis. Larry: some projects have CI runs that use Address Sanitizing. Fuzz testing would be dynamic code analysis, OpenEXR meets that definition by being part of Google Fuzz Testing.
            * Runtime assertions need to be checked during dynamic analysis
        * John: is it fair to say that the heavyweight ones are around code coverage and dynamic analysis? Larry: some projects haven't gotten around to it.
    * Silver Level
        * To be more efficient, even on the TAC slack, announce we will be looking at Silver, and solicit, look through the list ahead of time, if there are any you are unsure, we can jump straight to them, and attack those in order of most concern. JF to write that up.
* Static Analysis Tools
    * Missing projects added to ASWF SonarCloud organization (need to remember to do this when a new project moves to ASWF GH org): [https://sonarcloud.io/organizations/academysoftwarefoundation/projects](https://sonarcloud.io/organizations/academysoftwarefoundation/projects)
    * MaterialX using free for open source license of PVS-Studio
        * Can we extend this to other projects?
    * MaterialX also using cppcheck
        * Other projects?
* GHA Dashboard and analytics, any interest?
    * [Data source for LFX Dash](https://docs.linuxfoundation.org/lfx/insights/supported-data-sources#coming-soon) (visibility into LFX roadmap?)
    * [GitHub - chriskinsman/github-action-dashboard: A dashboard to keep track of the status of your GitHub Actions](https://github.com/chriskinsman/github-action-dashboard): where to host small servers?
    * SaaS solution: [Meercode](https://meercode.io/)
* Bonus topic: should we try to do anything about libpng?
    * Settle on a viable, better maintained fork (is there such a thing?)
    * Encourage ASWF projects to move to a different implementation (any ASWF projects use libpng directly?)
    * Add native libpng support to OIIO

## Follow Ups

* [https://www.sigstore.dev/](https://www.sigstore.dev/) : is this the new LF code signing platform? (Andrew)

## Tools
