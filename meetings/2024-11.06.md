---
title: 2024-11-06 
parent: Meetings
---

# ASWF CI Working Group

Meeting:   06 November 2024

[https://zoom-lfx.platform.linuxfoundation.org/meeting/97730566101?password=cb28b3b9-f744-46d0-ab69-d9f75f1b8668](https://zoom-lfx.platform.linuxfoundation.org/meeting/97730566101?password=cb28b3b9-f744-46d0-ab69-d9f75f1b8668)

## Attendees

* Jean-Francois Panisset, VES Technology Committee
* Andrew Grimberg, LF RelEng
* Larry Gritz, Sony Imageworks / OSL / OIIO

## Apologies

*

## New items

* 2025 images
  * No significant process
  * OpenVDB 12.0 released, last major component for 2025 platform
  * OIIO 3.0.0
    * Larry: if all goes well, no more betas / rcs, "final" release on Friday
    * Still doing monthly releases going forward on a set schedule
    * 3.0.0 will be the release family that gets more than critical updates / fully supported
    * Only critical bugs back ported back to 2.5
  * Mostly working on Conan 2 transition
    * [Conan Center no longer accepting Conan 1.x package updates](https://blog.conan.io/2024/09/30/Conan-Center-will-stop-receiving-updates-for-Conan-1.html)
    * Overall "better" but different
    * Better support for platform installed dependencies
    * Relative value of vendoring recipes from Conan Center Index vs maintaining patches
      * Larry: haven't applied patches. Try to vendor only small things, some distributions get grouchy if you vendor something they have packages for. Perhaps some obscure vendor only libraries. JF: yes, only talking about the package recipe. Larry: maybe just vendor it instead of applying patches so we can see the code in the repo, patches are harder to interpret, you want to see the recipe. JF: I think that's the argument, add a comment about version it's based on.
  * Conan (only) builds for more projects
    * ocio
    * oiio
    * openvdb
    * osl
    * usd
    * xstudio
    * Waiting for Qt6 merge into OpenRV

* NanoVDB and Position Independent Executables
  * [OpenVDB PR#1926](https://github.com/AcademySoftwareFoundation/openvdb/pull/1926)
  * [aswf-docker Issue #228](https://github.com/AcademySoftwareFoundation/aswf-docker/issues/228)
  * Considered "best practice" for security: [Compiler POptions Hardening Guide for C and C++](https://best.openssf.org/Compiler-Hardening-Guides/Compiler-Options-Hardening-Guide-for-C-and-C++.html)
  * RHEL / Rocky mostly build with -fPIE, but not default in gcc, or llvm
  * Could be other incompatibility with CUDA libraries
  * Larry: avoid turning it on by default, ask the projects to do this. If we set it up to default, people building outside our CI won't get it? Better to force them to do it. JF: could be that's not what projects release from? Larry: growing number of projects release their Python wheels from CI. JF: releases could be from a Ubuntu build. Larry: so better to call for it explicitly. But some of the projects may not do the work. There's probably a CMake flag to set, so everyone needs to have that. JF: could submit patches to projects.
  * JF: will reach out to NanoVDB to ask if they've made any progress and identified if there are other compiler options / CUDA issues.
  * Larry: a reason to push it to the projects, provide the CMake option, they are in better position to see if it solves their problem. Rebuilding gcc / llvm is "too much work", projects should really be adding this themselves.

* For pay runner budget
  * Temporarily (?) raised from $1500/month to $3000/month
    * Andrew: earlier this year when we ran into an issue, got authorization to increase from $1500 to $3000 for a month, dropped it back down. Have been running under budget for a while. Last couple of months we ran out of budget, bumped it up to $3K so CI can keep running. John authorized $3K per month until end of the year. But don't know what's the budget for next year.
    * Larry: mostly chewed up by OpenVDB? Andrew: GitHub has released beta support for sub organizations, have it on the LF Enterprise GitHub, seems to be working fine. I don't see the bills on that. Could talk to our GitHub reps to see if we can turn it on with ASWF, but would have to move OpenVDB to a separate org.
    * Larry: how do keep it so a project running over budget doesn't prevent other projects. Andrew: only granularity would be organization based, not sure if there will be a per-repo budget. Larry: do you feel that OpenVDB has ability to be more frugal? Are they considering it to be an issue? Andrew: not 100% certain. Would be nice if we had someone from project to talk about it.
    * Majority of the cost is Windows builders. JF: Windows builders are 2x, and the compilers are slower. Larry: even on OIIO, CI on Linux can do a full build + dependencies + test suite in 12-15 minutes, on Windows they may not finish in an hour.
    * Larry: hopefully project can put effort to see if there's anything they can do on their side. Andrew: could disallow premium builders to specific repos. But they need it! Larry: not saying anything they do is frivolous of course! Want to minimize impact.
  * Better visibility into usage in GitHub, but not costs
    * [Viewing GitHub Actions metrics for your organization](https://docs.github.com/en/enterprise-cloud@latest/organizations/collaborating-with-groups-in-organizations/viewing-github-actions-metrics-for-your-organization)
  * How do we manage this holistically across ASWF projects?
    * JF Would be good to have a global document.
    * Larry: I have yet to get OSL or OIIO working on paid GPU runners, and they both need it. Recently on OSL we broke a GPU code path due to GPU CI. When we do (after OIIO 3.0.0 release), those projects will need to start using paid minutes. Usage will only go up.
    * Andrew: still on credit card billing, since we have an enterprise account, we could switch to invoice based account, so costs will "go through"... Can still set a spending limit, main roadblock is that if we go past $3K, have to go through a lot of process to raise credit card limit to $3K.
    * Larry: could also be a surprise to governing board.
    * Andrew: would still have a spending limit, easier to ask John to temporarily raise limit. We are 6 days into November, have already spent $1680 this month.
    * Larry: when this came up in TAC meeting and agreed to raise the limit, recollection is that OpenVDB representative said it's because of 12.0.0 VFX Platform release. Wonder if that prediction is true and their needs are down? Maybe they have more cycles to put into tightening the screws?
    * Larry: Perhaps could get corporate sponsorship? JF: how about Microsoft?
    * Andrew: downloaded latest report.
    * Larry: can bring this up at Board level
    * Andrew: stats provided by GitHub are attached to a username
    * JF: wonder how users attached to schedule runs. Andrew: not sure we have scheduled runs using paid runners
    * [GitHub Runner Costs CSV viewer](https://austenstone.github.io/github-actions-usage-report)
    * Andrew: can only get CSV usage reports as an org / enterprise level admin
    * Most of the cost was between Oct 30 and Nov 2nd (around $1500), working to 12.0.0 release on Saturday Nov 2nd
    * Larry: can easily reach those numbers with a decent sized CI matrix
  * Linux / Windows on ARM is for-pay only for now
  * Andrew: we have some ways of working with this. ASWF has Amazon credits, primarily for DPEL, also used for CodeBuild for OCIO (and NanoVDB needs newer GPUs). We could shift some loads to AWS, but those credits are primarily for DPEL. We could get credits in other clouds. Team at LF has been playing around with GitHub ARC, "Actions Runner Controller", which is what GH is running on top of Azure, runs in Kubernetes, spin up / spin down. Do those clouds have the hardware we need. Only place we've played with this is PyTorch, but they stopped using it. GitHub ARC has ability to "scale to zero", but there's still the small K8S infrastructure that has to sit there and do "stuff", so a small ongoing cost. But significantly cheaper than a full CI infrastructure. We could push on this more, RelEng has been looking at this to get off Jenkins, have more control in K8S than in GHA. Not saying it's the perfect solution, but it's an option we could explore more. We could also go with Amazon CodeBuild, but then just shifting where the payments are going, can we get more credits from AWS.
  * Andrew: with ARC, can use GitHub runner image, so don't have to manage your own images. It's a control plan for running GitHub runners, which already have the GitHub runner daemon. Which is why you can't run GitHub Actions on a private runner with a different architecture not supported by GitHub.
  * AWS CodeBuild is more expensive than larger runners, but we have credits provided by AWS. For the last two years, credits have covered all costs for DPEL + minor cost from OCIO. So we're covering a fair amount of the AWS cost.
  * JF: could we use VEXXhost for GitHub ARC? Andrew: they have an ARC look-alike, but not as fully featured. All based on VMs, doesn't work as well. But could spin up K8S.
  * [GitHub Arc documentation](https://github.com/actions/actions-runner-controller)

* Ideas on sending email from GitHub Actions
  * LF mail relay?

## Follow Ups

* Custom images for larger GHA runners
  * Any updates?

## Tools and Links

* [Binary Optimization and Layout Tool BOLT and the Linux kernel](https://lwn.net/SubscriberLink/993828/eb9b437bf7604da3/)
* [GitHub Universe 2024 Conference](https://githubuniverse.com/)
* [Solving Sudoku in Python Packaging](https://github.com/konstin/sudoku-in-python-packaging)
  * [And in SPK](https://github.com/spkenv/spk/pull/1141)
