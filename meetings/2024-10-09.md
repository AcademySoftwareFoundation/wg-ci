---
title: 2024-10-09 
parent: Meetings
---

# ASWF CI Working Group

Meeting:   09 October 2024

[https://zoom-lfx.platform.linuxfoundation.org/meeting/97730566101?password=cb28b3b9-f744-46d0-ab69-d9f75f1b8668](https://zoom-lfx.platform.linuxfoundation.org/meeting/97730566101?password=cb28b3b9-f744-46d0-ab69-d9f75f1b8668)

## Attendees

* Jean-Francois Panisset, VES Technology Committee
* Andrew Grimberg, LF RelEng
* Stephen Mackenzie, NVIDIA / Rez
* Aloys Baillet, NVIDIA
* Ben Giles, Caligra
* Larry Gritz, Sony Imageworks / OSL / OIIO
* Jean-Christphe Morin, Rez

## Apologies

*

## New items

* 2024.2 Docker Images released
  * update latest / preview / draft tags for Docker images
  * update Python dependencies (resolve dependabot PRs)
  * update pylint and fix pylint / pytest warnings
  * Fix SonarCloud scanning
  * Conan 1.65 (was 1.64)
  * Expat 2.6.3 (was 2.5.0) to address CVEs CVE-2024-45492 CVE-2024-45491 CVE-2024-45490
  * fixes #196 : ci-openrv build container. OpenRV doesn't build yet, waiting for Qt6 support. For now openrv builds in non-default review group.
  * fixes #150 : rename master branch to main
  * fixes #218 : only attempt to use larger runners when running in context of ASWF GitHub org.
  * fixes #221 : ci-usd now includes Python dependencies
  * fixes #148 : Vulkan SDK and runtime now included in all images,   initially required for ci-openrv, but useful in general. Also Qt now built with Vulkan support
  * CUDA 12.6.1 (was 12.3.0)
    * See below for possible NVIDIA driver version issue
  * Java 17 (was 11) for ci-opencue image
  * Imath 3.1.12 (was 3.1.11)
  * MaterialX 1.39.1 (was 1.38.10)
  * OpenImageIO 2.15.16.0 (was 2.15.15.0)
  * OpenShadingLanguage 1.13.11.0 (was 1.13.10.0)
  * Python 3.11.10 (was 3.11.9)
  * USD 24.08 (was 24.05)
    * Had to apply single PR patch to allow to compile against MaterialX 1.39.1, [result may not be fully functional](https://academysoftwarefdn.slack.com/archives/C02HJH53RN3/p1728194370601199)
    * Wanted to prioritize latest MaterialX version
  * Larry: have not seen any breakage in OIIO or OSL. JF: is OIIO now using ci-oiio? Larry: using ci-osl for some of them, have tried the ci-oiio but rush onto it that the container sizes were the same. Not getting the OSL didn't cut down on container init time / size. But for those builds where I used it is seemed to work. OIIO is a dependency of OSL, so the dependencies are similar. OIIO may not need LLVM, but it's there in the base image. pugixml doesn't matter to me, I use it header only, so time to grab is next to nothing. It's the really big things I can't build from source I really want. But still come out ahead on time. Would be nice to have working docker-squash to remove NVIDIA bits we don't need.
  * Andrew: for these containers, have you been doing disk optimization before you capture the end of it? Every command line in a Dockerfile is a separate slice, all operations that happen in that file are captured permanently in the container size. JF: built using docker buildx, captured as Conan packages.
  * Aloys: we do follow best practices of disabling yum cache when installing packages, make sure not to add unnecessary things to the base image, but the base is big.

* 2025 images
  * ASWF major releases are now available (OpenVDB still hitting 1 Nov deadline?)
  * Transition to Conan 2: lots of changes, impact unclear for now
  * Should Clang be in the base images? Should we still maintain 2 Clang versions?
    * Larry: possibly not a reason to have 2 versions per year, in the past LLVM may have had a big API switch so we needed to switch to a new API to test, but may have morphed to twice a year. I don't feel I need every version of Clang.
    * JF: I was aiming for 18/19? Larry: if you can only do one, do the latest.
    * Aloys: I think it was more an accident, tried to have a few, realized it was too much, brought it down to 2.
    * JF: now that LLVM/Clang is a Conan package, projects that need it could just pull it in, using Conan dependency mechanism. Aloys: yes, could be worth trying. JF: oiio base image could not have clang in it for instance. Larry: don't have a clear view of performance tradeoff of downloading from Conan vs having it already in the container, or that the difference is worth it. What's nice about the containers for the VFX Platform is that I know that what's in the containers is locked down. Aloys: could depend on bandwidth to our own Artifactory instance vs Docker Hub. Downloading clang on top of an image that doesn't have it could be slightly longer?
    * Aloys: could also have images with and without Clang. But a lot more work.
    * Larry: not sure that makes enough of a difference to ask for this to expand the matrix.
  * Convert more packages to Conan-only
    * OIIO
    * OCIO
    * OSL
    * OpenVDB
  * More build containers
    * OpenFX
    * xStudio
    * OpenAssetIO
  * GitHub Actions optimizations and dependencies
    * Don't launch "container" jobs for Conan-only packages
  * OneTBB may need to be separate Conan packages from TBB
    * Unclear if ASWF projects using TBB can be built against OneTBB
    * No experience on this topic
    * Ben: depends on the machine it's deployed on. objdump sometimes sees which version it is pulling, how it's installed and built.
    * Larry: there's a lot of things that have stayed the same, so anything that uses the basic functionality may not see the difference. But packages that use more sophisticated parts may see the transition as an incompatibility.
  * JF: aiming before end of year

* GPU runner topics
  * OpenVDB needs INT8 / TF32 support not on T4 GPUs on GHA GPU for pay runners
    * "small" runners on AWS CodeBuild have A10G GPUs which support those data formats
    * OpenVDB needs to be setup for CodeBuild: did they submit a request? Andrew: yes, OpenVDB submitted a ticket.
  * 2024.2 containers updated to CUDA 12.6.1, requires NVIDIA driver 560.35 or newer, may require updating GPU base images (TBD)
    * Andrew: we don't yet have control over the base image. We do have access to the custom runner images. Still haven't read through the documentation. That doesn't get us access to the newer GPU instances on Azure. Larissa shared that access to A10 GPUs would be available in January.
    * JF: can "self update" the NVIDIA driver before entering container, but that's gross. Custom image would help.

* TAC revisiting Working Groups concept
  * [Evolving our working groups program #798](https://github.com/AcademySoftwareFoundation/tac/issues/798)
  * Should WGs producing artifacts really be projects?
  * What would the CI WG look like as a ASWF project? Would we get more participation / resources? Can we sustain the "overhead"?
  * Wait until Larry is back to discuss this.
  * Ben: do you want the full burden of being a project? Probably as important as any of the individual projects, but it is a deliverable. We do use them in research side of production. Not the same as some of the working groups focussed on a particular "vertical", this one is an actual deliverable. Can be argued both ways. Want to make sure the work continues.
  * Larry: not only is CI WG a good candidate, but also the canonical example of a WG that should be a project. We do have a repo and code and artifacts, we are producing IP. There's desire for groups that do that to have the same legal structure. When the foundation was started, original concept of WGs was limited time / imited scope, for instance the python3. Elevating it to a project gives it TAC representation, and represents that it isn't a temporary thing, so I think it's totally a project. On the other end, "what is a WG" has expanded, what's behaving like a project we want to make them real projects with project privileges, others are ongoing but may just need a zoom meeting and slack channel, more like a Special Interest Group, not producing code. Maybe the Zero Trust WG, that's the idea of how to split WGs into 3 chunks.
  * Larry: with the SIG thing, wanted to make threshold very low to spin one up.
  * Larry: We've been operating as a project as a long time. JC: [OpenSSF](https://openssf.org/community/openssf-working-groups/) is like that, they have SIGs, WGs and projects.
  * Larry: the issue of OpenSSF requirements didn't come up. But we need to meet the spirit of the projects.
  * JC: could we have an official project for the VFX Platform docker images, and keep CI WG separate? Larry: what does CI WG do? JC: the stuff we do today, we can own the aswf-docker images? Larry: what's the benefit of both a WG and Project? JC: would CI be a project, or the project would be the docker images? Larry: it would be the whole thing. Not every minute of a TSC meeting is what we change in the code, we also talk about the common interests. This has long since past the "CI" name, we don't need to break it up into too many parts.
  * Ben: it's very valuable so needs to go on
  * JC: could make sense to have an "infrastructure" project, this is the time to change the name.
  * Larry: on the day this was set up, we made a CI WG, we didn't know what we would be doing. Original purpose was how to figure out a shared approach to CI. That's long solved, but we're now maintaining this shared resource. The WG part ended a long time ago.
  * Larry: nothing set in stone, just an idea we were floating. Some WGs looking a lot like projects, but the label we put on this doesn't change what we do, but nice to have recognition to be recognized as a "real" project?
  * JC: you only get a representative if you are graduated. Larry: come in as incubating, but we should be able to graduate quickly.
  * Ben: should be a quick incubation, figure out what bits of OpenSSF requirements need to be met. Maybe there is more work. We may be able to provide some resources. I'm sure other people would be the same if there's a shortfall of resources, at least to get past incubation.
  * JF: is there a timeframe? Larry: not currently. No mandate, just is this a change that will serve the groups we are talking about.

* Managing our larger runners budget
  * Any ideas on doing this better?
  * Page on CI WG Wiki to keep track of builds using larger runners?
  * Can we surface costs and running spend?
  * Andrew: when I pull an audit, I get which workflow consummed how much time, I have a way to do that, but it's non trivial. No easy solution. JC: dashboard at org level? Andrew: can see some of that at org level, but not as good as what JF is asking? JC: but a good start, also a custom role so you can assign people who can see that info? Could be a first step, something to work with.
  * JF: would be great to get email notification of who much a run cost.

* Ideas on sending email from GitHub Actions
  * LF mail relay?

## Follow Ups

* NuGet support in Artifactory for xStudio builds
  * [LF Helpdesk Ticket IT-27186](https://jira.linuxfoundation.org/plugins/servlet/desk/portal/2/IT-27196)

* Recurring issues with growing size of aswf-docker build containers and very limited disk space on free GHA runners
  * Initial success using [docker-squash](https://github.com/goldmann/docker-squash) to shrink base image after removing Nsight Compute GUI debugger, saves over 1GB, aiming to support this for VFX 2025

* Enabling [CodeQL alerts in GitHub Actions](https://github.blog/changelog/2024-07-16-ai-powered-autofixes-for-historical-codeql-alerts-are-now-in-public-beta/)
  * GitHub asked if we are interested, we said yes, but haven't heard anything back.
  * [Now available for all public repos](https://github.blog/changelog/2024-09-18-now-available-for-free-on-all-public-repositories-copilot-autofix-for-codeql-code-scanning-alerts/)

* Custom images for larger GHA runners
  * From presentation last month
  * Any updates?
  * See above discussion

## Tools and Links

* [Fuzzing Tutorial](https://github.com/antonio-morales/Fuzzing101) which uses libtiff, VLC, libexif
  * Uses [AFLplusplus](https://github.com/AFLplusplus/AFLplusplus) fuzzer
* PyPI namespacing PEPs
  * [PEP 755](https://discuss.python.org/t/pep-755-implicit-namespace-policy-for-pypi/63191)
  * [PEP 752](https://discuss.python.org/t/pep-752-implicit-namespaces-for-package-repositories/63192)
  * JC: no one knows what they want, there are competing ideas, so was suggesting that LF could be a good voice to state what we want.
  * JC: unclear if tied to organizations that few have access to, whether it will be a paid feature. Several different approaches. You can read the threads but good luck! Maybe we'll end up with namespaces, big push from NVIDIA to do that, maybe it will be paid, maybe it will be free.
* [GitHub Attestation](https://github.blog/news-insights/product-news/introducing-artifact-attestations-now-in-public-beta/)
* [Watch out for phishing emails claiming to be from GitHub](https://ianspence.com/blog/2024-09/github-email-hijack/)
* [Use case for ARM runners](https://academysoftwarefdn.slack.com/archives/C0169RX7MMK/p1727971372505199)
